{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9380bf40-e3b4-4fcc-a2b5-5b7be2147b4d",
   "metadata": {},
   "source": [
    "Za one koji pomazu sa snimanjem dataseta: Ispod, u PREFIKS upisite svoje ime u formatu \"ImePrezime_\", i pokrenite sve na poslednje dugme na meniju(Restart the kernel and run all cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7600cb-7e80-44be-8b3c-669c90a70e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIKS = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd07ed2-c3ae-46ff-92aa-eadbd651b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "POCETNI_UZORAK_BR = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189bb29-f6af-4146-ad61-0eee937297a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Camera_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d7a4e-c3fd-4492-9ff5-26b34b8ab9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_EPOCHS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec247b-953f-4c68-9998-1ead4bfc205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FOLDER_NAME = \"Logs2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e98325-c954-4a40-b8df-9f8431fa106f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f2994-df56-43b1-8ce7-50a54e9baa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python mediapipe scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec78ef0-17a6-4d5e-a355-a561cfd2f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84007a-cb23-4ec4-a82d-22ef015b6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join(PREFIKS+'MP_Data') \n",
    "\n",
    "# Actions that we try to detect\n",
    "if os.path.exists(DATA_PATH):\n",
    "    sign_labels = np.array(os.listdir(DATA_PATH))\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n",
    "\n",
    "# Folder start\n",
    "start_folder = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4ae7c-d583-4d7d-8f9a-3da3ef64aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496afb27-fa51-4ebd-b369-69b8db4e417d",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77fba2-c3b5-4b56-8ee5-262edd19bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_record_number_for_sign(sign_label):\n",
    "    if os.path.exists(os.path.join(DATA_PATH, sign_label)):\n",
    "        number_of_records = len(os.listdir(os.path.join(DATA_PATH, sign_label))) \n",
    "        if number_of_records>0:\n",
    "            folder_names = os.listdir(os.path.join(DATA_PATH, sign_label))\n",
    "            folder_numbers = [ [int(el) for el in name.split('_') if el.isdigit()] for name in folder_names]\n",
    "            \n",
    "            max_record_name = np.max(np.array( folder_numbers  ).astype(int)) + 1\n",
    "            record_num = max_record_name if max_record_name > number_of_records else number_of_records\n",
    "        else:\n",
    "            record_num = number_of_records\n",
    "    else:\n",
    "        record_num = 0\n",
    "    return record_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa175d1-eed2-44ef-bb8a-aa5815f968f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional setup of folders\n",
    "\n",
    "def setup_folders_for_alphabet(path=\"MP_Data\"):\n",
    "    \n",
    "    azbuka = ['a', 'b', 'v', 'g', 'd', 'đ', 'e', 'ž', 'z', 'i', 'j', 'k', 'l', 'lj', 'm', 'n', 'nj', 'o', 'p', 'r', 's', 't', 'ć', 'u', 'f', 'h', 'c', 'č','dž', 'š']\n",
    "    for slovo in azbuka:\n",
    "        if POCETNI_UZORAK_BR is not None:\n",
    "            record_num = POCETNI_UZORAK_BR\n",
    "        else:\n",
    "            record_num = get_next_record_number_for_sign(slovo)\n",
    "        \n",
    "        try: \n",
    "            os.makedirs(os.path.join(path, slovo, str(record_num)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b146a2c-4f86-4213-9acd-91f8da588f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    setup_folders_for_alphabet(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753f703-b69e-422f-a680-7a9f0ec2b0bc",
   "metadata": {},
   "source": [
    "# 2. Keypoint functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0524d466-4a88-4cca-a46c-1af65900d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b5dc40-3432-4f17-938f-6c555541c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424adb1c-cd2e-40e1-b08d-879d1344fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_hands.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_hands.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d3807-6067-41f0-a36a-30aa93bab1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    '''mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) '''\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(160,44,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(160,88,150), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    if results.left_hand_landmarks is not None:\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    if results.right_hand_landmarks is not None:\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363e6e9-1567-4a23-b7b2-6cd7790193e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    #face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, lh, rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d46f95-d635-45ed-8ec5-2f3cd87dc499",
   "metadata": {},
   "source": [
    "# Preprocess Data and Create Labels and Features¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdeb5b5-a6f4-4384-b3f6-a74096749383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73f1b0-fa8d-4864-b83a-f63883181a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels_and_features(_test_size=0.1):\n",
    "    sign_labels = np.array(os.listdir(DATA_PATH))\n",
    "    label_map = {label:num for num, label in enumerate(sign_labels)}\n",
    "    sequences, labels = [], []\n",
    "    for sign in sign_labels:\n",
    "        for sequence in os.listdir(os.path.join(DATA_PATH, sign)):\n",
    "            video = []\n",
    "            for frame_num in range(sequence_length):\n",
    "                res = np.load(os.path.join(DATA_PATH, sign, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "                video.append(res)\n",
    "            sequences.append(video)\n",
    "            labels.append(label_map[sign])\n",
    "    X = np.array(sequences)\n",
    "    y = to_categorical(labels).astype(int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=_test_size)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09fa8ce-5529-4212-8130-f372c552309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels_and_features(num_of_labels=-1, num_of_sequences=-1,_test_size=0.1):\n",
    "    if num_of_labels == -1:\n",
    "        num_of_labels = len(os.listdir(DATA_PATH))\n",
    "    \n",
    "    sign_labels = np.array(os.listdir(DATA_PATH))[:num_of_labels]\n",
    "    label_map = {label:num for num, label in enumerate(sign_labels)}\n",
    "    sequences, labels = [], []\n",
    "    for sign in sign_labels:\n",
    "        if num_of_sequences == -1:\n",
    "            nmbr_of_seq = len(os.listdir(os.path.join(DATA_PATH, sign)))\n",
    "        else:\n",
    "            nmbr_of_seq = num_of_sequences\n",
    "        for sequence in os.listdir(os.path.join(DATA_PATH, sign))[:nmbr_of_seq]:\n",
    "            video = []\n",
    "            for frame_num in range(sequence_length):\n",
    "                res = np.load(os.path.join(DATA_PATH, sign, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "                video.append(res)\n",
    "            sequences.append(video)\n",
    "            labels.append(label_map[sign])\n",
    "    X = np.array(sequences)\n",
    "    y = to_categorical(labels).astype(int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=_test_size)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d893094-064e-4b6f-b9ad-3a9dc3f5d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir(os.path.join(DATA_PATH, 'a'))[:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb98ea88-402b-4a99-ac5c-b83d2011a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sign_labels = np.array(os.listdir(DATA_PATH))\n",
    "#label_map = {label:num for num, label in enumerate(sign_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48d390-6906-4d02-a456-a191f4f545c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98b9ef-1420-488d-9bba-e646b895caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a83fdd-5826-4331-9e7d-b2ab8eb1e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d443f3e-440a-4008-bf28-ea826117e4be",
   "metadata": {},
   "source": [
    "# Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c51400-d27c-4ff6-a299-3afc8815f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c2619-518f-4195-8e8b-dd2c61e7fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(LOG_FOLDER_NAME)\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2ba5f-fec6-4ec3-ba1e-b0cf8dfca026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(sign_labels=np.array(os.listdir(DATA_PATH)) ,path='action.keras'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,258)))\n",
    "    model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "    model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(sign_labels.shape[0], activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    model.load_weights(path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b29614-dc15-4175-b875-b714bdc2de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_model(model,X_test, y_test,labels):\n",
    "    ypred = model.predict(X_test)\n",
    "    ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "    ypred = np.argmax(ypred, axis=1).tolist()\n",
    "\n",
    "    #print(ytrue)\n",
    "    #print(ypred)\n",
    "    print(len(labels))\n",
    "    print(\"recall\")\n",
    "    print(recall_score(ytrue, ypred,average='weighted'))\n",
    "    print(\"precision\")\n",
    "    print(precision_score(ytrue, ypred,average='weighted'))\n",
    "    print(\"f1\")\n",
    "    print(f1_score(ytrue, ypred,average='weighted'))\n",
    "    \n",
    "    print(\"Accuracy score:\")\n",
    "    print(accuracy_score(ytrue, ypred) )\n",
    "    print(\"multilabel_confusion_matrix\")\n",
    "    print(multilabel_confusion_matrix(ytrue, ypred))\n",
    "\n",
    "    \n",
    "    conf_matrix = confusion_matrix(ytrue, ypred)\n",
    "    print(\"conf matrix\")\n",
    "    print(conf_matrix)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n",
    "                              display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecbb125-acfb-4f13-b154-80eeb5e85cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_model(load_model(sign_labels=np.array(os.listdir(DATA_PATH))[:20], path='let20sekv20epoha200.keras') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9df2c-5cc7-4a2f-826f-982c828a7f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_new_model(epoh_num=400,sign_labels=np.array(os.listdir(DATA_PATH))):\n",
    "    #sign_labels = sign_labels[:20]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,258)))\n",
    "    model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "    model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(sign_labels.shape[0], activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    X_train, X_test, y_train, y_test = create_labels_and_features(_test_size=0.2)\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=epoh_num, callbacks=[tb_callback])\n",
    "    test_model(model,X_test,y_test,sign_labels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa44c6-5e82-4a11-be15-2fb4c8249ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sign_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf274ea3-ffd5-4874-ac51-9a07ac937507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name='action.keras'):\n",
    "    model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797e450-01ca-4b67-8aea-ba02f0426afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(train_new_model(epoh_num=400),'let30sekvNepoha400.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116e124-1c5f-4085-957d-6098a947ee27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Evaluation using Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca0538-548e-4c04-a7bb-4870b99fc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0bb8eb-b363-4f04-8ca8-0f81188079ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ba1c9-6c0f-4a56-9ef8-cc6b0a14062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "#yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6846d-2fce-4bf0-9a44-6c51c4c62f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca713f-4b0c-4f2e-9cd4-3626e248631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d35f1c6-4a06-4852-8060-96cb7389b871",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Tkinter GUI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da28a3-55d9-4602-a879-0ccc89de3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import Image, ImageTk \n",
    "\n",
    "def input_textbox(options):\n",
    "    text = \"initial value\"\n",
    "    master = Tk()\n",
    "    master.title(\"Izabrati znak\") \n",
    "    master.geometry('500x500') \n",
    "    \n",
    "    Label(master, text='Unesi znak:').grid(row=0)\n",
    "    entry = Entry(master)\n",
    "    entry.grid(row=0, column=1)\n",
    "    entry.focus_set()\n",
    "\n",
    "    options_list = [option for option in options]\n",
    "\n",
    "    value_inside = StringVar(master) \n",
    "\n",
    "    value_inside.set(\"Select an Option\") \n",
    "    \n",
    "    if len(options_list)>0:\n",
    "        question_menu = OptionMenu(master, value_inside, *options_list) \n",
    "        question_menu.grid(row=1) \n",
    "\n",
    "    def callback():\n",
    "        nonlocal text\n",
    "        text = entry.get()\n",
    "        if(text == \"\") and (value_inside.get() != \"Select an Option\"):\n",
    "            text = value_inside.get()\n",
    "        master.destroy()\n",
    "    \n",
    "    OK_button = Button(master, text = \"OK\", width = 10, command = callback)\n",
    "    OK_button.grid(row=2)\n",
    "    \n",
    "    master.mainloop()\n",
    "    print(text)\n",
    "    print('aaa')\n",
    "    return text\n",
    "\n",
    "def manual_textbox():\n",
    "    master = Tk()\n",
    "    master.title(\"Manual\") \n",
    "    master.geometry('500x500') \n",
    "\n",
    "    Label(master, text='Press Q or Esc to exit program',anchor=W, width=50).grid(row=0)\n",
    "    Label(master, text='Press R to start recording keypoints',anchor=W, width=50).grid(row=1)\n",
    "    Label(master, text='Press Space to start Live sign recognition',anchor=W, width=50).grid(row=2)\n",
    "    Label(master, text='Press N to go back to plain live feed',anchor=W, width=50).grid(row=3)\n",
    "    \n",
    "    def callback():\n",
    "        master.destroy()\n",
    "\n",
    "    def callback_train():\n",
    "        model = None\n",
    "        model = train_new_model()\n",
    "        save_model(model)\n",
    "        master.destroy()\n",
    "        \n",
    "    \n",
    "    close_button = Button(master, text = \"Proceed to live feed\", command = callback)\n",
    "    close_button.grid(row=4,column=1)\n",
    "    train_button =  Button(master, text = \"Train updated model and proceed\", command = callback_train)\n",
    "    train_button.grid(row=4,column=0)\n",
    "    \n",
    "    mainloop()\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dca590-2f6d-4370-86e7-2aa9b3488123",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Supportig functions for GUI / drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc98a76-77e2-49a4-a439-8c859dab6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115b4c8-8266-479a-95af-a4ed05566584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_printable_labels(label):\n",
    "    if label == 'Đ':\n",
    "        return 'Dj'\n",
    "    elif label == 'Ž':\n",
    "        return 'Zh'\n",
    "    elif label == 'Ć':\n",
    "        return 'Cj'\n",
    "    elif label == 'Č':\n",
    "        return 'Ch'\n",
    "    elif label == 'Dž':\n",
    "        return 'Dzh'\n",
    "    elif label == 'Š':\n",
    "        return 'Sh'\n",
    "    else:\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9137d972-96bd-4cfd-a32c-7a6aaf02083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_vizualization(res, sign_labels, input_frame):\n",
    "    if probability_vizualization.colors is None:\n",
    "        probability_vizualization.colors = [(  int(100+random()*155), int(100+random()*155), int(100+random()*155)) for sign in sign_labels]\n",
    "    output_frame = input_frame.copy()\n",
    "    \n",
    "    if len(res)>5:\n",
    "        \n",
    "        indexes = np.argpartition(res, -5)[-5:]\n",
    "        for num, prob in enumerate( res[indexes]):\n",
    "            cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), probability_vizualization.colors[indexes[num]], -1)\n",
    "            cv2.putText(output_frame, cv_printable_labels( sign_labels[indexes[num]]  ), (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    else:   \n",
    "        for num, prob in enumerate( res):\n",
    "            cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), probability_vizualization.colors[num], -1)\n",
    "            cv2.putText(output_frame, cv_printable_labels( sign_labels[num] ), (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "    return output_frame\n",
    "probability_vizualization.colors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df7bf5-10fd-43b1-951c-e9b657747f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResizeWithAspectRatio(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv2.resize(image, dim, interpolation=inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf982d5-343c-4bca-a635-93c24537fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91483cf0-9abd-4947-8d83-6335b28766bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_draw_and_return_landmarks(cap,hands,pose):\n",
    "# Read feed\n",
    "    ret, frame = cap.read()\n",
    "    image = cv2.flip(frame, 1) \n",
    "    \n",
    "    # Make detections\n",
    "    image, hand_results = mediapipe_detection(image, hands)\n",
    "    image, pose_results = mediapipe_detection(image, pose)\n",
    "    \n",
    "    left_hand_landmarks = None\n",
    "    right_hand_landmarks = None\n",
    "    landmarks_results = namedtuple(\"landmarks_results\", \"pose_landmarks left_hand_landmarks right_hand_landmarks\")\n",
    "    \n",
    "    if hand_results.multi_handedness is not None:\n",
    "        for handedness, hand_landmarks in zip(hand_results.multi_handedness, hand_results.multi_hand_landmarks):\n",
    "            #print(handedness.classification)\n",
    "            #print(hand_landmarks)\n",
    "            if handedness is not None:\n",
    "                if handedness.classification[0].label == \"Left\":\n",
    "                    left_hand_landmarks = hand_landmarks\n",
    "                if handedness.classification[0].label == \"Right\":\n",
    "                    right_hand_landmarks = hand_landmarks\n",
    "    landmarks_results.left_hand_landmarks = left_hand_landmarks\n",
    "    landmarks_results.right_hand_landmarks = right_hand_landmarks\n",
    "    landmarks_results.pose_landmarks = pose_results.pose_landmarks\n",
    "\n",
    "    # Draw landmarks\n",
    "    draw_styled_landmarks(image, landmarks_results)\n",
    "    \n",
    "    #for recognition\n",
    "    all_landmarks = extract_keypoints(landmarks_results)\n",
    "    \n",
    "    return all_landmarks, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ee6c9-b4a9-4daa-abd2-8e2ae5fd0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_textbox_window(master,options):\n",
    "    text = \"\"\n",
    "    window = Toplevel(master)\n",
    "    window.title(\"Izabrati znak\") \n",
    "    window.geometry('300x300') \n",
    "    \n",
    "    Label(window, text='Unesi znak:').grid(row=0)\n",
    "    entry = Entry(window)\n",
    "    entry.grid(row=0, column=1)\n",
    "    entry.focus_set()\n",
    "\n",
    "    options_list = [option for option in options]\n",
    "\n",
    "    value_inside = StringVar(window) \n",
    "\n",
    "    value_inside.set(\"Select an Option\") \n",
    "    \n",
    "    if len(options_list)>0:\n",
    "        question_menu = OptionMenu(window, value_inside, *options_list) \n",
    "        question_menu.grid(row=1) \n",
    "\n",
    "    def callback():\n",
    "        nonlocal text\n",
    "        text = entry.get()\n",
    "        if(text == \"\") and (value_inside.get() != \"Select an Option\"):\n",
    "            text = value_inside.get()\n",
    "        window.destroy()\n",
    "    \n",
    "    OK_button = Button(window, text = \"OK\", width = 10, command = callback)\n",
    "    OK_button.grid(row=2)\n",
    "\n",
    "    window.wait_window()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c96f3-6f76-4a83-9d8d-fcd120c63810",
   "metadata": {},
   "source": [
    "# GUI main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667cab9a-3c8a-40d6-9195-3278293af8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image\n",
    "from enum import Enum\n",
    "\n",
    "CountdownTime = 1.5\n",
    "\n",
    "class Mode(Enum):\n",
    "    LIVE = 0\n",
    "    SELECT_SIGN = 1\n",
    "    CAPTURE_MODE = 2\n",
    "    COUNTDOWN = 3\n",
    "    CAPTURING = 4\n",
    "    LIVE_RECOGNITION = 5\n",
    "\n",
    "class MainWindow:\n",
    "    root = None\n",
    "    text_label_value = None\n",
    "    label_with_image = None\n",
    "    cap = None\n",
    "    mode = Mode.LIVE\n",
    "    sequence = []\n",
    "    sentence = []\n",
    "    predictions = []\n",
    "    threshold = 0.5\n",
    "    model = None\n",
    "    #model = load_model(path='let10sekv60epoha600.keras')\n",
    "    sign_labels = None\n",
    "    sign_label = \"\"\n",
    "    saved_models_path = 'Saved Models'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.main_window_start()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        self.root = None\n",
    "        self.text_label_value = None\n",
    "        self.label_with_image = None\n",
    "        self.cap = None\n",
    "        self.mode = Mode.LIVE\n",
    "        self.sequence = []\n",
    "        self.sentence = []\n",
    "        self.predictions = []\n",
    "        self.threshold = 0.5\n",
    "        self.model = None\n",
    "        self.sign_labels = None\n",
    "        self.sign_label = \"\"\n",
    "        self.saved_models_path =  os.path.join(DATA_PATH,'Saved Models')\n",
    "    \n",
    "    \n",
    "    def main_window_update_camera(root,label_with_image, image):\n",
    "        #main_window_start.key = None\n",
    "        photo_image = ImageTk.PhotoImage(image=Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGBA) ) ) \n",
    "        \n",
    "        label_with_image.photo_image = photo_image\n",
    "        label_with_image.configure(image=photo_image) \n",
    "        return main_window_start.key\n",
    "\n",
    "    def mode_processing(self,image, all_landmarks):     \n",
    "        match self.mode:\n",
    "            case Mode.LIVE:\n",
    "                \n",
    "                cv2.putText(image, 'Live Mode', (50,50), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 3, cv2.LINE_AA)\n",
    "            case Mode.SELECT_SIGN:\n",
    "                \n",
    "                cv2.putText(image, 'Select sign', (50,50), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 3, cv2.LINE_AA)\n",
    "                if os.path.exists(DATA_PATH):\n",
    "                    self.options = os.listdir(DATA_PATH)\n",
    "                else:\n",
    "                    self.options = []\n",
    "                self.sign_label = input_textbox_window(self.root,self.options)\n",
    "                print(self.sign_label)\n",
    "                if self.sign_label != \"\":\n",
    "                    self.mode = Mode.CAPTURE_MODE\n",
    "            case Mode.CAPTURE_MODE:\n",
    "    \n",
    "                cv2.putText(image, 'Record frames for sign:{}'.format( cv_printable_labels( self.sign_label)  ), (50,50), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 3, cv2.LINE_AA)\n",
    "                cv2.putText(image, \"Press S to start, R to go back to sign selection\", (100,100), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 3, cv2.LINE_AA)\n",
    "                \n",
    "                   \n",
    "            case Mode.COUNTDOWN:\n",
    "                \n",
    "                cv2.putText(image, 'Record frames for sign:{}'.format( cv_printable_labels( self.sign_label)  ), (50,50), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 3, cv2.LINE_AA)\n",
    "                cv2.putText(image, \"{}\".format(CountdownTime-int(time.time()-self.start_time)), (150,150), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                if time.time()-self.start_time >= CountdownTime:\n",
    "                    self.mode = Mode.CAPTURING\n",
    "                    self.frame_number = 0\n",
    "                    \n",
    "            case Mode.CAPTURING:\n",
    "                if self.frame_number == 0:\n",
    "                    self.record_num = get_next_record_number_for_sign(self.sign_label)\n",
    "                    os.makedirs(os.path.join(DATA_PATH, self.sign_label, str(self.record_num)))\n",
    "                \n",
    "                cv2.putText(image, 'Recording frame {}/30 for sign {}, video {}'.format(self.frame_number, cv_printable_labels(self.sign_label), self.record_num), (50,50), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 3, cv2.LINE_AA)\n",
    "                \n",
    "                #keypoints = extract_keypoints(landmarks_results)\n",
    "                \n",
    "                npy_path = os.path.join(DATA_PATH, self.sign_label, str(self.record_num), str(self.frame_number))\n",
    "                np.save(npy_path, all_landmarks)\n",
    "                \n",
    "                self.frame_number+=1\n",
    "                if self.frame_number>30:\n",
    "                    self.frame_number = 0\n",
    "                    self.mode = Mode.CAPTURE_MODE\n",
    "                    \n",
    "            case Mode.LIVE_RECOGNITION:\n",
    "                self.sequence.append(all_landmarks)\n",
    "                self.sequence = self.sequence[-30:]\n",
    "                \n",
    "                if self.model is None:\n",
    "                    self.model = load_model(self.sign_labels)\n",
    "                if len(self.sequence) == 30:\n",
    "                    res = self.model.predict(np.expand_dims(self.sequence, axis=0))[0]\n",
    "                    self.predictions.append(np.argmax(res))\n",
    "                    last_10_predicts = np.unique(self.predictions[-10:])\n",
    "                    \n",
    "                    if last_10_predicts[0]==np.argmax(res) and last_10_predicts.shape[0] == 1: \n",
    "                        if res[np.argmax(res)] > self.threshold: \n",
    "\n",
    "                            if self.sign_labels[np.argmax(res)] != 'No_sign':\n",
    "                                if len(self.sentence) > 0: \n",
    "                                    if self.sign_labels[np.argmax(res)] != self.sentence[-1]:\n",
    "                                        self.sentence.append(self.sign_labels[np.argmax(res)])\n",
    "                                else:\n",
    "                                    self.sentence.append(self.sign_labels[np.argmax(res)])\n",
    "        \n",
    "                    if len(self.sentence) > 10: \n",
    "                        self.sentence = self.sentence[-10:]\n",
    "                    #probabilities\n",
    "                    image = probability_vizualization(res, self.sign_labels, image)\n",
    "        \n",
    "        #cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        #cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "        #       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        self.tkinter_text_value.set(self.sentence)\n",
    "    \n",
    "        return image\n",
    "\n",
    "    \n",
    " \n",
    "    def main_window_start(self):\n",
    "        if os.path.exists(DATA_PATH):\n",
    "            self.sign_labels = np.array(os.listdir(DATA_PATH))\n",
    "            \n",
    "        \n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1200)\n",
    "        self.root = Tk()\n",
    "        self.tkinter_text_value = StringVar(self.root) \n",
    "\n",
    "  \n",
    "        self.root.title(\"\") \n",
    "        self.root.geometry('965x680+300+100') \n",
    "        self.tkinter_text_value.set(\"\") \n",
    "        Label(self.root, text='Press Q or Esc to exit program',anchor=W, width=50).grid(row=0,sticky=W,columnspan=2)\n",
    "        Label(self.root, text='Press R to start recording keypoints',anchor=W, width=50).grid(row=1,sticky=W,columnspan=2)\n",
    "        Label(self.root, text='Press Space to start Live sign recognition(Load model first)',anchor=W, width=50).grid(row=2,sticky=W,columnspan=2)\n",
    "        Label(self.root, text='Press N to go back to plain live feed',anchor=W, width=50).grid(row=3,sticky=W,columnspan=2)\n",
    "        Label(self.root, text='Press B to delete a letter',anchor=W, width=50).grid(row=4,sticky=W,columnspan=2)\n",
    "        Label(self.root, textvariable=self.tkinter_text_value, font=(\"Arial\", 16, \"bold\"), bg='lightblue' ).grid(row=6,columnspan=5)\n",
    "        \n",
    "        self.label_with_image = Label(self.root)\n",
    "        self.label_with_image.grid(row=7,columnspan=5)\n",
    "    \n",
    "    \n",
    "        def callback_close():\n",
    "            self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            self.root.destroy()\n",
    "            \n",
    "    \n",
    "        def callback_train():\n",
    "            save_model(train_new_model())\n",
    "\n",
    "        def clear_sentence():\n",
    "            self.sentence = []\n",
    "\n",
    "        def callback_load_model():\n",
    "            #del self.model\n",
    "            filename = input_textbox_window(self.root, os.listdir( self.saved_models_path ) )\n",
    "            self.model = load_model(path = os.path.join(self.saved_models_path,filename) )\n",
    "\n",
    "\n",
    "        \n",
    "        train_button =  Button(self.root, text = \"Train updated model and save it\", command = callback_train)\n",
    "        train_button.grid(row=5,column=0)\n",
    "        clear_button = Button(self.root, text = \"Clear sentence\", command = clear_sentence)\n",
    "        clear_button.grid(row=5,column=2)\n",
    "        close_button = Button(self.root, text = \"Close\", command = callback_close)\n",
    "        close_button.grid(row=5,column=3)\n",
    "        load_model_button = Button(self.root, text = \"Load model\", command = callback_load_model)\n",
    "        load_model_button.grid(row=5,column=1)\n",
    "\n",
    "        def keypress_processing(event):\n",
    "            key=event.char\n",
    "            if key == 'q': #ord('q'):\n",
    "                self.cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                self.root.destroy()\n",
    "            elif key == 'r': #ord('r'):\n",
    "                self.mode = Mode.SELECT_SIGN\n",
    "            elif key == 'n': #ord('n'):\n",
    "                self.mode = Mode.LIVE\n",
    "            elif key == ' ': #space\n",
    "                self.mode = Mode.LIVE_RECOGNITION\n",
    "            elif key == 's':\n",
    "                 #start countdown and record\n",
    "                self.start_time = time.time()\n",
    "                self.mode = Mode.COUNTDOWN\n",
    "            elif key == 'd':\n",
    "                self.sentence = self.sentence[:-1]\n",
    "                \n",
    "          \n",
    "\n",
    "        with mp_hands.Hands() as hands, mp_pose.Pose() as pose:\n",
    "            def video_stream():\n",
    "                all_landmarks, frame = get_frame_draw_and_return_landmarks(self.cap,hands,pose)\n",
    "\n",
    "                frame = self.mode_processing(frame,all_landmarks)\n",
    "                \n",
    "                \n",
    "                cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "                img = Image.fromarray(cv2image)\n",
    "                imgtk = ImageTk.PhotoImage(image=img,master=self.root)\n",
    "                self.label_with_image.imgtk = imgtk\n",
    "                self.label_with_image.configure(image=imgtk)\n",
    "                self.label_with_image.after(1, video_stream) \n",
    "            \n",
    "\n",
    "            self.root.bind('<Key>', keypress_processing)\n",
    "            video_stream()\n",
    "            self.root.mainloop()\n",
    "        #end with\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f4544a-0a43-4904-b6dc-46a7c86d8caa",
   "metadata": {},
   "source": [
    "# Run main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b74847-0d70-478f-bfc5-49b189ce10c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "instance = MainWindow()\n",
    "del instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6601462d-446d-4ce9-b11a-b2ef3dfd6216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
